{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321c714c",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ 04 â€” Agents Hands-On in Python (Option A)\n",
    "\n",
    "This notebook gives you **practical, code-focused building blocks** for Agentic AI in Python:\n",
    "\n",
    "- Implementing a minimal **ReAct-style agent loop**\n",
    "- Defining **tools** as Python callables with schemas\n",
    "- Adding **memory** and simple **planning**\n",
    "- Sketching a **multi-agent** pattern\n",
    "- Showing how this connects to **RAG** and **MCP** later\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625fac02",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Setup\n",
    "\n",
    "Weâ€™ll assume:\n",
    "\n",
    "- Python 3.10+\n",
    "- An `openai`-compatible client (can be OpenAI, Azure, or a local shim)\n",
    "- Environment variable `OPENAI_API_KEY` (or equivalent) is set\n",
    "\n",
    "For now, all calls are structured but we keep actual LLM calls **minimal and pluggable**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b1fbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "# If you have an OpenAI-compatible client, you can adapt this later.\n",
    "# For now, we leave a placeholder function for \"llm_complete\" to keep this notebook self-contained.\n",
    "\n",
    "def llm_complete(system_prompt: str, messages: List[Dict[str, str]]) -> str:\n",
    "    \"\"\"Placeholder LLM completion.\n",
    "\n",
    "    Replace this with a real call, for example:\n",
    "\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI()\n",
    "    resp = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt}, *messages],\n",
    "    )\n",
    "    return resp.choices[0].message.content\n",
    "    \"\"\"\n",
    "    # For now, just echo a simple string so the loop is testable without a real LLM.\n",
    "    return \"THOUGHT: I will call the 'echo' tool.\n",
    "ACTION: echo\n",
    "ACTION_INPUT: {\"text\": \"Hello from mock LLM\"}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4cf5bc",
   "metadata": {},
   "source": [
    "\n",
    "## 2. A Minimal Tool Abstraction\n",
    "\n",
    "We define a simple **Tool** concept:\n",
    "\n",
    "- `name`\n",
    "- `description`\n",
    "- `func(input_dict) -> output_dict`\n",
    "- optional `schema` (for documentation/validation later)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45c0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Tool:\n",
    "    name: str\n",
    "    description: str\n",
    "    func: Callable[[Dict[str, Any]], Dict[str, Any]]\n",
    "\n",
    "    def __call__(self, tool_input: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        return self.func(tool_input)\n",
    "\n",
    "\n",
    "class ToolRegistry:\n",
    "    def __init__(self):\n",
    "        self._tools: Dict[str, Tool] = {}\n",
    "\n",
    "    def register(self, tool: Tool):\n",
    "        if tool.name in self._tools:\n",
    "            raise ValueError(f\"Tool '{tool.name}' is already registered.\")\n",
    "        self._tools[tool.name] = tool\n",
    "\n",
    "    def get(self, name: str) -> Optional[Tool]:\n",
    "        return self._tools.get(name)\n",
    "\n",
    "    def list_tools(self) -> List[Tool]:\n",
    "        return list(self._tools.values())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f1e93",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Example Tools\n",
    "\n",
    "Weâ€™ll define some simple tools:\n",
    "\n",
    "- `echo` â€“ echoes text back\n",
    "- `add_numbers` â€“ adds two numbers\n",
    "- `search_notes` â€“ fake search over an in-memory list (stand-in for RAG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d9bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-memory \"notes\" for a fake search tool\n",
    "NOTES = [\n",
    "    {\"id\": 1, \"content\": \"Python agents can use tools and memory.\"},\n",
    "    {\"id\": 2, \"content\": \"RAG combines retrieval with generation.\"},\n",
    "    {\"id\": 3, \"content\": \"MCP provides a capability layer via tools.\"},\n",
    "]\n",
    "\n",
    "def echo_tool(input_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    text = str(input_dict.get(\"text\", \"\"))\n",
    "    return {\"text\": text}\n",
    "\n",
    "def add_numbers_tool(input_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    a = float(input_dict.get(\"a\", 0))\n",
    "    b = float(input_dict.get(\"b\", 0))\n",
    "    return {\"result\": a + b}\n",
    "\n",
    "def search_notes_tool(input_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    query = str(input_dict.get(\"query\", \"\")).lower()\n",
    "    matches = [n for n in NOTES if query in n[\"content\"].lower()]\n",
    "    return {\"matches\": matches}\n",
    "\n",
    "registry = ToolRegistry()\n",
    "registry.register(Tool(name=\"echo\", description=\"Echo back text\", func=echo_tool))\n",
    "registry.register(Tool(name=\"add_numbers\", description=\"Add two numbers\", func=add_numbers_tool))\n",
    "registry.register(Tool(name=\"search_notes\", description=\"Search in-memory notes\", func=search_notes_tool))\n",
    "\n",
    "[ (t.name, t.description) for t in registry.list_tools() ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8bf8a0",
   "metadata": {},
   "source": [
    "\n",
    "## 4. A Minimal ReAct-Style Agent Loop\n",
    "\n",
    "We implement a **single-agent loop**:\n",
    "\n",
    "- The agent receives a user query\n",
    "- It keeps a **history** of:\n",
    "  - user messages\n",
    "  - thoughts\n",
    "  - tool calls\n",
    "  - observations\n",
    "- The LLM outputs:\n",
    "  - `THOUGHT: ...`\n",
    "  - `ACTION: tool_name` (or `NONE`)\n",
    "  - `ACTION_INPUT: {...}` (JSON)\n",
    "- The agent executes the tool (if any), then feeds observations back to the LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf394c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "REACT_SYSTEM_PROMPT = \"\"\"You are a helpful agent that can use tools.\n",
    "\n",
    "You will respond using this format:\n",
    "\n",
    "THOUGHT: <your reasoning>\n",
    "ACTION: <tool_name or NONE>\n",
    "ACTION_INPUT: <JSON object with arguments>\n",
    "\n",
    "Available tools will be described to you. If no tool is needed, set ACTION to NONE.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_tool_list(tools: List[Tool]) -> str:\n",
    "    lines = []\n",
    "    for t in tools:\n",
    "        lines.append(f\"- {t.name}: {t.description}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "def parse_react_response(text: str) -> Tuple[str, str, Dict[str, Any]]:\n",
    "    thought_match = re.search(r\"THOUGHT:(.*)\", text)\n",
    "    action_match = re.search(r\"ACTION:(.*)\", text)\n",
    "    input_match = re.search(r\"ACTION_INPUT:(.*)\", text, re.DOTALL)\n",
    "\n",
    "    thought = thought_match.group(1).strip() if thought_match else \"\"\n",
    "    action = action_match.group(1).strip() if action_match else \"NONE\"\n",
    "    raw_input = input_match.group(1).strip() if input_match else \"{}\"\n",
    "\n",
    "    try:\n",
    "        action_input = json.loads(raw_input)\n",
    "    except json.JSONDecodeError:\n",
    "        action_input = {\"raw\": raw_input, \"parse_error\": True}\n",
    "\n",
    "    return thought, action, action_input\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class AgentStep:\n",
    "    user: Optional[str] = None\n",
    "    thought: Optional[str] = None\n",
    "    action: Optional[str] = None\n",
    "    action_input: Optional[Dict[str, Any]] = None\n",
    "    observation: Optional[Dict[str, Any]] = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SimpleAgent:\n",
    "    tools: ToolRegistry\n",
    "    max_steps: int = 5\n",
    "    memory: List[AgentStep] = field(default_factory=list)\n",
    "\n",
    "    def run(self, user_query: str) -> str:\n",
    "        \"\"\"Run a ReAct-style loop until the agent stops or hits step limit.\"\"\"\n",
    "        self.memory.clear()\n",
    "        self.memory.append(AgentStep(user=user_query))\n",
    "\n",
    "        for step_idx in range(self.max_steps):\n",
    "            messages = self._build_messages(user_query)\n",
    "            tool_list_str = format_tool_list(self.tools.list_tools())\n",
    "            messages.append({\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"User question: {user_query}\\n\\nAvailable tools:\\n{tool_list_str}\",\n",
    "            })\n",
    "\n",
    "            raw = llm_complete(REACT_SYSTEM_PROMPT, messages)\n",
    "            thought, action, action_input = parse_react_response(raw)\n",
    "\n",
    "            current_step = AgentStep(\n",
    "                user=user_query if step_idx == 0 else None,\n",
    "                thought=thought,\n",
    "                action=action,\n",
    "                action_input=action_input,\n",
    "            )\n",
    "\n",
    "            if action.upper() == \"NONE\":\n",
    "                # Final answer is the thought or separate final message if you want to extend format\n",
    "                self.memory.append(current_step)\n",
    "                return thought or raw\n",
    "\n",
    "            tool = self.tools.get(action)\n",
    "            if not tool:\n",
    "                current_step.observation = {\"error\": f\"Unknown tool '{action}'\"}\n",
    "                self.memory.append(current_step)\n",
    "                return f\"Error: unknown tool '{action}'.\"\n",
    "\n",
    "            obs = tool(action_input or {})\n",
    "            current_step.observation = obs\n",
    "            self.memory.append(current_step)\n",
    "\n",
    "        return \"I reached the maximum number of steps without finishing.\"\n",
    "\n",
    "    def _build_messages(self, user_query: str) -> List[Dict[str, str]]:\n",
    "        messages: List[Dict[str, str]] = []\n",
    "        # You can add a compressed memory summary here in a more advanced version.\n",
    "        for s in self.memory:\n",
    "            if s.user:\n",
    "                messages.append({\"role\": \"user\", \"content\": s.user})\n",
    "            if s.thought:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": f\"THOUGHT: {s.thought}\"})\n",
    "            if s.action:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": f\"ACTION: {s.action}\"})\n",
    "            if s.observation is not None:\n",
    "                messages.append({\"role\": \"user\", \"content\": f\"OBSERVATION: {s.observation}\"})\n",
    "        return messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5492eab",
   "metadata": {},
   "source": [
    "\n",
    "### Test the SimpleAgent with Mocked LLM\n",
    "\n",
    "Remember, weâ€™re using a **mock** `llm_complete` that always calls the `echo` tool.  \n",
    "You can later swap `llm_complete` with a real client.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097201e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = SimpleAgent(tools=registry, max_steps=3)\n",
    "answer = agent.run(\"Say hi using the echo tool.\")\n",
    "answer, agent.memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e73ee7",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Adding Simple Memory\n",
    "\n",
    "We now extend the agent with:\n",
    "\n",
    "- A **conversation memory** summary (simple version: concatenation)\n",
    "- The idea that memory can influence future reasoning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccb3980",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MemoryAwareAgent(SimpleAgent):\n",
    "    def _summarize_memory(self) -> str:\n",
    "        # Very naive memory summarization\n",
    "        parts = []\n",
    "        for idx, s in enumerate(self.memory):\n",
    "            if s.user:\n",
    "                parts.append(f\"[User] {s.user}\")\n",
    "            if s.thought:\n",
    "                parts.append(f\"[Thought {idx}] {s.thought}\")\n",
    "            if s.action:\n",
    "                parts.append(f\"[Action {idx}] {s.action} {s.action_input}\")\n",
    "            if s.observation is not None:\n",
    "                parts.append(f\"[Obs {idx}] {s.observation}\")\n",
    "        return \"\\n\".join(parts)\n",
    "\n",
    "    def _build_messages(self, user_query: str) -> List[Dict[str, str]]:\n",
    "        messages: List[Dict[str, str]] = []\n",
    "        if self.memory:\n",
    "            summary = self._summarize_memory()\n",
    "            messages.append({\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"Conversation summary so far:\\n{summary}\",\n",
    "            })\n",
    "        return messages\n",
    "\n",
    "mem_agent = MemoryAwareAgent(tools=registry, max_steps=3)\n",
    "answer2 = mem_agent.run(\"Search notes about RAG and tell me what you find.\")\n",
    "answer2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee971d7e",
   "metadata": {},
   "source": [
    "\n",
    "> ðŸ”Ž **Note:**  \n",
    "> This is intentionally simple. In a production-grade system you would:\n",
    "> - Use vector stores for long-term memory\n",
    "> - Use summarization models for compression\n",
    "> - Store memory externally (DB, Redis, etc.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c37078",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Sketching a Multi-Agent Pattern (Manager â†’ Worker)\n",
    "\n",
    "Here we sketch how a **manager agent** could delegate to a **worker agent**.\n",
    "\n",
    "We keep this minimal and focus on structure, not perfect LLM logic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ab2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WorkerAgent(SimpleAgent):\n",
    "    role: str = \"worker\"\n",
    "\n",
    "    def run_task(self, task: str) -> str:\n",
    "        return super().run(task)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ManagerAgent(SimpleAgent):\n",
    "    worker: WorkerAgent = None  # type: ignore\n",
    "\n",
    "    def run(self, user_query: str) -> str:\n",
    "        # Very naive: manager decomposes into a single sub-task for the worker.\n",
    "        sub_task = f\"Perform the main work for: {user_query}\"\n",
    "        worker_result = self.worker.run_task(sub_task)\n",
    "        # Manager then wraps worker result as final answer.\n",
    "        return f\"As manager, I delegated the work. Worker result: {worker_result}\"\n",
    "\n",
    "\n",
    "worker = WorkerAgent(tools=registry, max_steps=3)\n",
    "manager = ManagerAgent(tools=registry, max_steps=2, worker=worker)\n",
    "\n",
    "manager_answer = manager.run(\"Help me understand how agents use tools.\")\n",
    "manager_answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62f32b",
   "metadata": {},
   "source": [
    "\n",
    "## 7. How This Connects to RAG and MCP\n",
    "\n",
    "This notebook focuses on *pure Python agents*, but in your full ecosystem:\n",
    "\n",
    "- **RAG Universe** provides:\n",
    "  - Retrieval tools (search, get_document, etc.)\n",
    "  - Evaluation tools (RAGAS, LLM-as-judge)\n",
    "\n",
    "- **MCP Universe** provides:\n",
    "  - A tool / capability layer for:\n",
    "    - filesystem\n",
    "    - HTTP\n",
    "    - DB\n",
    "    - RAG servers\n",
    "    - DevOps & Finance tools\n",
    "\n",
    "- **Agents Universe (this one)**:\n",
    "  - Uses those tools via:\n",
    "    - ReAct-style loops\n",
    "    - Plannerâ€“executor patterns\n",
    "    - Multi-agent systems\n",
    "\n",
    "In later notebooks (08, 09, 10), you will:\n",
    "\n",
    "- Turn the **fake `search_notes` tool** into real RAG calls  \n",
    "- Turn the **simple `Tool` abstraction** into MCP tool calls  \n",
    "- Implement full **Agentic RAG** and **Agents + MCP** systems.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
