{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa5c03b0",
   "metadata": {},
   "source": [
    "\n",
    "# 10 — Full RAG + Agents + MCP (Integrated Demo)\n",
    "\n",
    "This notebook demonstrates a **small but complete integrated pipeline**:\n",
    "\n",
    "- RAG backend over a tiny corpus\n",
    "- Planner → Retriever → Answer agents\n",
    "- MCP-style ToolRegistry (calculator + search)\n",
    "- LangGraph workflow to orchestrate:\n",
    "  - RAG path\n",
    "  - Tool path\n",
    "  - Final answer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bac091",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3fe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install langchain langchain-openai langchain-community chromadb langgraph --quiet\n",
    "\n",
    "import os\n",
    "from typing import Dict, Any, TypedDict, Callable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "emb = OpenAIEmbeddings()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe886be",
   "metadata": {},
   "source": [
    "## 1. RAG Backend (Tiny Corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973ecd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.makedirs(\"full_rag_agents_mcp_data\", exist_ok=True)\n",
    "\n",
    "with open(\"full_rag_agents_mcp_data/corpus.txt\", \"w\") as f:\n",
    "    f.write(\"RAG retrieves external documents and feeds them into the LLM for grounded answers.\\n\")\n",
    "    f.write(\"Agents can plan, decide which tools to call, and manage multi-step reasoning.\\n\")\n",
    "    f.write(\"MCP provides a protocol for exposing tools and calling them from agents.\\n\")\n",
    "\n",
    "loader = TextLoader(\"full_rag_agents_mcp_data/corpus.txt\")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "chunks = splitter.split_documents(docs)\n",
    "\n",
    "db = Chroma.from_documents(chunks, emb)\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 3})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9b8a22",
   "metadata": {},
   "source": [
    "## 2. RAG Agents (Planner → Retriever → Answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c68115d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def planner_agent(question: str) -> str:\n",
    "    prompt = f\"\"\"You are a Planner Agent.\n",
    "\n",
    "Write a short plan (1–2 sentences) describing how to answer this question\n",
    "using the RAG knowledge base.\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "def retriever_agent(plan: str) -> str:\n",
    "    docs = retriever.get_relevant_documents(plan)\n",
    "    return \"\\n\".join(d.page_content for d in docs)\n",
    "\n",
    "def answer_agent(question: str, context: str) -> str:\n",
    "    prompt = f\"\"\"You are an Answer Agent.\n",
    "\n",
    "Use ONLY the context to answer the question concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "    return llm.invoke(prompt).content\n",
    "\n",
    "# Quick test\n",
    "print(planner_agent(\"Explain how RAG, agents, and MCP relate.\"))\n",
    "ctx_test = retriever_agent(\"Retrieve RAG + agents + MCP relationship.\")\n",
    "print(answer_agent(\"Explain how RAG, agents, and MCP relate.\", ctx_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8dcd11",
   "metadata": {},
   "source": [
    "## 3. MCP-Style ToolRegistry + Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60bc892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ToolRegistry:\n",
    "    def __init__(self):\n",
    "        self.tools: Dict[str, Callable[..., Any]] = {}\n",
    "\n",
    "    def register(self, name: str, fn: Callable[..., Any]):\n",
    "        self.tools[name] = fn\n",
    "\n",
    "    def call(self, name: str, **kwargs) -> Any:\n",
    "        if name not in self.tools:\n",
    "            raise ValueError(f\"Tool '{name}' not found\")\n",
    "        return self.tools[name](**kwargs)\n",
    "\n",
    "tool_registry = ToolRegistry()\n",
    "\n",
    "# Example tools\n",
    "def tool_calculator(expression: str) -> str:\n",
    "    try:\n",
    "        result = eval(expression, {\"__builtins__\": {}})\n",
    "        return f\"Result of {expression} = {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "def tool_fake_search(query: str) -> str:\n",
    "    return f\"[Fake search results for '{query}': RAG docs, Agents docs, MCP docs]\"\n",
    "\n",
    "tool_registry.register(\"calculator\", tool_calculator)\n",
    "tool_registry.register(\"search\", tool_fake_search)\n",
    "\n",
    "print(tool_registry.call(\"calculator\", expression=\"2 + 3 * 10\"))\n",
    "print(tool_registry.call(\"search\", query=\"agentic RAG\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a6e79",
   "metadata": {},
   "source": [
    "## 4. Tool-Using Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass\n",
    "class ToolDecision:\n",
    "    tool_name: str\n",
    "    args: Dict[str, Any]\n",
    "\n",
    "class ToolAgent:\n",
    "    def __init__(self, llm: ChatOpenAI, registry: ToolRegistry):\n",
    "        self.llm = llm\n",
    "        self.registry = registry\n",
    "\n",
    "    def decide(self, question: str) -> ToolDecision | None:\n",
    "        q = question.lower()\n",
    "        if \"calculate\" in q or \"calc\" in q or any(c in q for c in [\"+\", \"-\", \"*\", \"/\"]):\n",
    "            expr = question.replace(\"calculate\", \"\").replace(\"calc\", \"\").strip()\n",
    "            return ToolDecision(tool_name=\"calculator\", args={\"expression\": expr or question})\n",
    "        if \"search\" in q or \"lookup\" in q or \"google\" in q:\n",
    "            return ToolDecision(tool_name=\"search\", args={\"query\": question})\n",
    "        return None\n",
    "\n",
    "    def run(self, question: str) -> str:\n",
    "        decision = self.decide(question)\n",
    "        if not decision:\n",
    "            # fallback: just let the LLM answer\n",
    "            return self.llm.invoke(question).content\n",
    "\n",
    "        tool_result = self.registry.call(decision.tool_name, **decision.args)\n",
    "        prompt = f\"\"\"You are an assistant that uses tools.\n",
    "\n",
    "User question:\n",
    "{question}\n",
    "\n",
    "Tool called: {decision.tool_name}\n",
    "Tool result:\n",
    "{tool_result}\n",
    "\n",
    "Explain the result clearly to the user.\n",
    "\"\"\"\n",
    "        return self.llm.invoke(prompt).content\n",
    "\n",
    "tool_agent = ToolAgent(llm, tool_registry)\n",
    "print(tool_agent.run(\"Calculate 10 * (5 + 2)\"))\n",
    "print(tool_agent.run(\"Search about MCP with agents\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53c4922",
   "metadata": {},
   "source": [
    "## 5. LangGraph Integrated Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c091382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FullState(TypedDict):\n",
    "    question: str\n",
    "    mode: str\n",
    "    plan: str\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "def router_node(state: FullState) -> FullState:\n",
    "    q = state[\"question\"].lower()\n",
    "    # Very simple routing heuristic: if math/search-like, use tools, else RAG\n",
    "    if any(x in q for x in [\"calculate\", \"calc\", \"+\", \"-\", \"*\", \"/\", \"search\", \"lookup\", \"google\"]):\n",
    "        state[\"mode\"] = \"TOOLS\"\n",
    "    else:\n",
    "        state[\"mode\"] = \"RAG\"\n",
    "    return state\n",
    "\n",
    "def rag_node(state: FullState) -> FullState:\n",
    "    plan = planner_agent(state[\"question\"])\n",
    "    ctx = retriever_agent(plan)\n",
    "    ans = answer_agent(state[\"question\"], ctx)\n",
    "    state[\"plan\"] = plan\n",
    "    state[\"context\"] = ctx\n",
    "    state[\"answer\"] = ans\n",
    "    return state\n",
    "\n",
    "def tool_node(state: FullState) -> FullState:\n",
    "    ans = tool_agent.run(state[\"question\"])\n",
    "    state[\"plan\"] = \"\"\n",
    "    state[\"context\"] = \"\"\n",
    "    state[\"answer\"] = ans\n",
    "    return state\n",
    "\n",
    "graph = StateGraph(FullState)\n",
    "graph.add_node(\"router\", router_node)\n",
    "graph.add_node(\"rag_flow\", rag_node)\n",
    "graph.add_node(\"tool_flow\", tool_node)\n",
    "\n",
    "graph.set_entry_point(\"router\")\n",
    "\n",
    "def branch_from_router(state: FullState):\n",
    "    if state[\"mode\"] == \"TOOLS\":\n",
    "        return \"tool_flow\"\n",
    "    return \"rag_flow\"\n",
    "\n",
    "graph.add_conditional_edges(\n",
    "    \"router\",\n",
    "    branch_from_router,\n",
    "    {\n",
    "        \"rag_flow\": \"rag_flow\",\n",
    "        \"tool_flow\": \"tool_flow\",\n",
    "    },\n",
    ")\n",
    "\n",
    "graph.add_edge(\"rag_flow\", END)\n",
    "graph.add_edge(\"tool_flow\", END)\n",
    "\n",
    "workflow = graph.compile()\n",
    "\n",
    "print(workflow.invoke({\"question\": \"Explain how RAG, agents, and MCP relate.\"}))\n",
    "print(workflow.invoke({\"question\": \"Calculate 7 * (3 + 4)\"}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d07f8",
   "metadata": {},
   "source": [
    "\n",
    "## End of Notebook 10 — Full RAG + Agents + MCP\n",
    "\n",
    "You now have:\n",
    "\n",
    "- A tiny RAG backend\n",
    "- Planner / Retriever / Answer agents\n",
    "- MCP-style tools and tool agent\n",
    "- LangGraph workflow that routes between RAG and tools\n",
    "\n",
    "This serves as a compact integrated example you can grow into a full system.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
