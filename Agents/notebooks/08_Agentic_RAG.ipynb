{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bf9d20d",
   "metadata": {},
   "source": [
    "\n",
    "# üõ∞Ô∏è 08 ‚Äî Agentic RAG (Agents + Retrieval-Augmented Generation)\n",
    "\n",
    "This notebook focuses **specifically** on combining:\n",
    "\n",
    "- **Agents** (from this Agents Universe)  \n",
    "- **RAG** (from your RAG Universe)  \n",
    "\n",
    "into **Agentic RAG** patterns.\n",
    "\n",
    "The goal is to:\n",
    "\n",
    "- Go beyond *‚Äúretrieve then answer‚Äù*  \n",
    "- Let an **agent plan, call retrieval tools, reflect, and iterate**  \n",
    "- Make retrieval **adaptive and intelligent**, not static  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0c8b0",
   "metadata": {},
   "source": [
    "\n",
    "## 1. What Is Agentic RAG?\n",
    "\n",
    "Classic RAG (from your RAG Universe):\n",
    "\n",
    "1. Embed documents  \n",
    "2. Retrieve top-k chunks for a query  \n",
    "3. Stuff chunks into context  \n",
    "4. Ask the LLM to answer  \n",
    "\n",
    "Agentic RAG:\n",
    "\n",
    "1. An **agent** reasons about the user‚Äôs goal  \n",
    "2. It **plans** what to retrieve (and where from)  \n",
    "3. It uses **retrieval tools** (one or more times)  \n",
    "4. It **reflects** on whether the retrieved context is enough  \n",
    "5. It may:\n",
    "   - refine the query  \n",
    "   - call other tools  \n",
    "   - do multi-hop retrieval  \n",
    "6. It synthesizes a final answer with **citations and explanations**  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce54a929",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Roles in an Agentic RAG System\n",
    "\n",
    "You can define several **agent roles**:\n",
    "\n",
    "- **User-Facing Answer Agent**\n",
    "  - Talks to the user  \n",
    "  - Orchestrates everything  \n",
    "  - Produces final answer  \n",
    "\n",
    "- **Retrieval Planner Agent**\n",
    "  - Decides:\n",
    "    - which index to query\n",
    "    - which filters to apply\n",
    "    - how many docs to retrieve  \n",
    "\n",
    "- **Query Rewriter Agent**\n",
    "  - Takes user query\n",
    "  - Generates better retrieval queries\n",
    "  - Can propose:\n",
    "    - expanded queries\n",
    "    - synonyms, related phrases  \n",
    "\n",
    "- **Context Selector Agent**\n",
    "  - Given many candidate chunks, picks the best ones  \n",
    "  - Optionally:\n",
    "    - diversifies sources\n",
    "    - removes duplicates  \n",
    "\n",
    "These can be:\n",
    "\n",
    "- separate agents (multi-agent)  \n",
    "- or behaviors inside a **single** configurable agent  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc9f8e3",
   "metadata": {},
   "source": [
    "\n",
    "## 3. RAG Tools Expected from the RAG Universe\n",
    "\n",
    "From your **RAG Universe**, we assume tools like:\n",
    "\n",
    "- `search_knowledge_base(query, top_k, filters)`  \n",
    "- `get_document_by_id(id)`  \n",
    "- `get_chunks_by_ids(ids)`  \n",
    "- Optional:\n",
    "  - `search_by_semantic(query, top_k)`\n",
    "  - `search_by_keyword(query, top_k)`\n",
    "  - `hybrid_search(query, top_k)`\n",
    "\n",
    "In this notebook we will create **placeholder functions** and show how an agent would use them.\n",
    "\n",
    "You can later wire these to your **real RAG pipelines**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6fa089",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Skeleton: RAG Tool Adapters in Python\n",
    "\n",
    "Below we sketch Python functions that wrap RAG retrieval as **tools** an agent can call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09c0224",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any, List\n",
    "\n",
    "# These are STUBS / PLACEHOLDERS.\n",
    "# Replace them with real calls to your RAG Universe (vector DB, DB, etc.)\n",
    "\n",
    "def rag_search_tool(input_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Search the knowledge base for relevant chunks.\n",
    "\n",
    "    Expected input:\n",
    "      {\n",
    "        \"query\": \"string\",\n",
    "        \"top_k\": 5,\n",
    "        \"filters\": { ...optional... }\n",
    "      }\n",
    "\n",
    "    Output (example shape):\n",
    "      {\n",
    "        \"results\": [\n",
    "          {\"id\": \"doc1#chunk3\", \"doc_id\": \"doc1\", \"score\": 0.87, \"snippet\": \"‚Ä¶\"},\n",
    "          ...\n",
    "        ]\n",
    "      }\n",
    "    \"\"\"\n",
    "    query = input_dict.get(\"query\", \"\")\n",
    "    top_k = int(input_dict.get(\"top_k\", 5))\n",
    "    filters = input_dict.get(\"filters\", {})\n",
    "\n",
    "    # TODO: connect to your real vector DB / RAG pipeline.\n",
    "    # For now, we just return a mock.\n",
    "    return {\n",
    "        \"results\": [\n",
    "            {\n",
    "                \"id\": \"doc1#chunk1\",\n",
    "                \"doc_id\": \"doc1\",\n",
    "                \"score\": 0.9,\n",
    "                \"snippet\": f\"Mock snippet for query='{query}' (top_k={top_k})\",\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "def rag_get_document_tool(input_dict: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Fetch a full document by ID (stub).\n",
    "\n",
    "    Input:\n",
    "      {\"doc_id\": \"doc1\"}\n",
    "\n",
    "    Output:\n",
    "      {\"doc_id\": \"doc1\", \"title\": \"...\", \"content\": \"...\"}\n",
    "    \"\"\"\n",
    "    doc_id = input_dict.get(\"doc_id\", \"unknown\")\n",
    "    # TODO: real DB / file lookup.\n",
    "    return {\n",
    "        \"doc_id\": doc_id,\n",
    "        \"title\": f\"Mock document {doc_id}\",\n",
    "        \"content\": \"Full document content would go here in a real system.\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4d4c3",
   "metadata": {},
   "source": [
    "\n",
    "> üîÅ In your **real implementation**, you‚Äôd import your RAG library / vector DB client and implement the body of these functions using:\n",
    ">\n",
    "> - pgvector / Postgres  \n",
    "> - Chroma / FAISS / Pinecone  \n",
    "> - LangChain retrievers  \n",
    "> - LlamaIndex query engines  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dead07",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Integrating RAG Tools with the Agent Tool System\n",
    "\n",
    "We now assume you are re-using the **Tool** / `ToolRegistry` abstractions from the Python hands-on notebook (04).\n",
    "\n",
    "Here is how you would register RAG tools as agent tools:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b990c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in same environment as 04, Tool & ToolRegistry are already defined.\n",
    "# Otherwise, you would re-import or redefine them.\n",
    "\n",
    "try:\n",
    "    registry  # type: ignore[name-defined]\n",
    "except NameError:\n",
    "    from dataclasses import dataclass\n",
    "    from typing import Callable, Dict, Any, List\n",
    "\n",
    "    @dataclass\n",
    "    class Tool:\n",
    "        name: str\n",
    "        description: str\n",
    "        func: Callable[[Dict[str, Any]], Dict[str, Any]]\n",
    "\n",
    "        def __call__(self, tool_input: Dict[str, Any]) -> Dict[str, Any]:\n",
    "            return self.func(tool_input)\n",
    "\n",
    "    class ToolRegistry:\n",
    "        def __init__(self):\n",
    "            self._tools: Dict[str, Tool] = {}\n",
    "\n",
    "        def register(self, tool: Tool):\n",
    "            self._tools[tool.name] = tool\n",
    "\n",
    "        def get(self, name: str):\n",
    "            return self._tools.get(name)\n",
    "\n",
    "        def list_tools(self) -> List[Tool]:\n",
    "            return list(self._tools.values())\n",
    "\n",
    "    registry = ToolRegistry()\n",
    "\n",
    "# Register RAG tools alongside other tools\n",
    "registry.register(Tool(\n",
    "    name=\"rag_search\",\n",
    "    description=\"Search the knowledge base (RAG) for relevant text chunks.\",\n",
    "    func=rag_search_tool,\n",
    "))\n",
    "\n",
    "registry.register(Tool(\n",
    "    name=\"rag_get_document\",\n",
    "    description=\"Get a full document by its ID.\",\n",
    "    func=rag_get_document_tool,\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbfe22",
   "metadata": {},
   "source": [
    "\n",
    "## 6. Agentic RAG Loop: High-Level Flow\n",
    "\n",
    "We now design a **ReAct-style Agentic RAG loop**:\n",
    "\n",
    "1. User asks a question  \n",
    "2. Agent:\n",
    "   - decides if it needs retrieval  \n",
    "   - possibly rewrites the query for retrieval  \n",
    "   - calls `rag_search` one or more times  \n",
    "   - inspects results  \n",
    "   - decides if more retrieval is needed  \n",
    "3. Agent synthesizes final answer, with:\n",
    "   - references (doc IDs, titles, etc.)  \n",
    "   - explanation of reasoning (optional)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cc7232",
   "metadata": {},
   "source": [
    "\n",
    "### 6.1 Prompting the Agent for Retrieval Decisions\n",
    "\n",
    "We extend the **system prompt**:\n",
    "\n",
    "- Tell the agent:\n",
    "  - when to use `rag_search`\n",
    "  - how many times\n",
    "  - how to decide if context is enough  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84c7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENTIC_RAG_SYSTEM_PROMPT = \"\"\"You are a careful, retrieval-aware assistant.\n",
    "\n",
    "You can use tools to search a knowledge base and fetch documents.\n",
    "\n",
    "Tools:\n",
    "- rag_search(query, top_k, filters?) -> returns candidate chunks\n",
    "- rag_get_document(doc_id) -> returns full document content\n",
    "\n",
    "Guidelines:\n",
    "- If the question requires factual or document-based knowledge, you MUST use rag_search at least once.\n",
    "- If initial results seem insufficient, you may:\n",
    "  - refine the query\n",
    "  - search again\n",
    "- Try not to call rag_search more than 3 times.\n",
    "- When you have enough information, stop using tools and provide a final answer with brief citations.\n",
    "\n",
    "Use this format at each step:\n",
    "THOUGHT: <your reasoning>\n",
    "ACTION: <tool_name or NONE>\n",
    "ACTION_INPUT: <JSON object>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9930c2",
   "metadata": {},
   "source": [
    "\n",
    "### 6.2 Using the Existing SimpleAgent with Agentic RAG Prompt\n",
    "\n",
    "We now reuse the `SimpleAgent` from the Python hands-on notebook, but with:\n",
    "\n",
    "- updated system prompt  \n",
    "- RAG tools in the registry  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab49e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assume SimpleAgent, parse_react_response, etc. are defined as in 04.\n",
    "# If not in the current environment, you'd import them.\n",
    "\n",
    "try:\n",
    "    SimpleAgent  # type: ignore[name-defined]\n",
    "except NameError:\n",
    "    # Minimal fallback stub to avoid execution errors; in real usage, import from 04.\n",
    "    from dataclasses import dataclass, field\n",
    "    from typing import List, Dict, Any, Optional, Tuple\n",
    "    import json, re\n",
    "\n",
    "    def llm_complete(system_prompt: str, messages: List[Dict[str, str]]) -> str:\n",
    "        # Placeholder simulated ReAct output\n",
    "        return \"THOUGHT: I will query the knowledge base.\n",
    "ACTION: rag_search\n",
    "ACTION_INPUT: {\"query\": \"mock\", \"top_k\": 1}\"\n",
    "\n",
    "    def parse_react_response(text: str) -> Tuple[str, str, Dict[str, Any]]:\n",
    "        thought_match = re.search(r\"THOUGHT:(.*)\", text)\n",
    "        action_match = re.search(r\"ACTION:(.*)\", text)\n",
    "        input_match = re.search(r\"ACTION_INPUT:(.*)\", text, re.DOTALL)\n",
    "        thought = thought_match.group(1).strip() if thought_match else \"\"\n",
    "        action = action_match.group(1).strip() if action_match else \"NONE\"\n",
    "        raw_input = input_match.group(1).strip() if input_match else \"{}\"\n",
    "        try:\n",
    "            action_input = json.loads(raw_input)\n",
    "        except json.JSONDecodeError:\n",
    "            action_input = {\"raw\": raw_input, \"parse_error\": True}\n",
    "        return thought, action, action_input\n",
    "\n",
    "    @dataclass\n",
    "    class AgentStep:\n",
    "        user: Optional[str] = None\n",
    "        thought: Optional[str] = None\n",
    "        action: Optional[str] = None\n",
    "        action_input: Optional[Dict[str, Any]] = None\n",
    "        observation: Optional[Dict[str, Any]] = None\n",
    "\n",
    "    @dataclass\n",
    "    class SimpleAgent:\n",
    "        tools: Any\n",
    "        max_steps: int = 5\n",
    "        memory: List[AgentStep] = field(default_factory=list)\n",
    "\n",
    "        def run(self, user_query: str) -> str:\n",
    "            self.memory.clear()\n",
    "            self.memory.append(AgentStep(user=user_query))\n",
    "            for _ in range(self.max_steps):\n",
    "                messages = []\n",
    "                for s in self.memory:\n",
    "                    if s.user:\n",
    "                        messages.append({\"role\": \"user\", \"content\": s.user})\n",
    "                    if s.thought:\n",
    "                        messages.append({\"role\": \"assistant\", \"content\": f\"THOUGHT: {s.thought}\"})\n",
    "                    if s.action:\n",
    "                        messages.append({\"role\": \"assistant\", \"content\": f\"ACTION: {s.action}\"})\n",
    "                    if s.observation is not None:\n",
    "                        messages.append({\"role\": \"user\", \"content\": f\"OBSERVATION: {s.observation}\"})\n",
    "                raw = llm_complete(AGENTIC_RAG_SYSTEM_PROMPT, messages)\n",
    "                thought, action, action_input = parse_react_response(raw)\n",
    "                step = AgentStep(thought=thought, action=action, action_input=action_input)\n",
    "                if action.upper() == \"NONE\":\n",
    "                    self.memory.append(step)\n",
    "                    return thought or raw\n",
    "                tool = self.tools.get(action)\n",
    "                if not tool:\n",
    "                    step.observation = {\"error\": f\"Unknown tool '{action}'\"}\n",
    "                    self.memory.append(step)\n",
    "                    return f\"Unknown tool '{action}'\"\n",
    "                obs = tool(action_input or {})\n",
    "                step.observation = obs\n",
    "                self.memory.append(step)\n",
    "            return \"Max steps reached\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bbae48",
   "metadata": {},
   "source": [
    "\n",
    "Now we can create an **Agentic RAG Agent** instance:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd6a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentic_rag_agent = SimpleAgent(tools=registry, max_steps=3)\n",
    "\n",
    "response = agentic_rag_agent.run(\"Explain what Agentic RAG is, based on the knowledge base.\")\n",
    "response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf51266",
   "metadata": {},
   "source": [
    "\n",
    "> üìù In a real environment, with a real `llm_complete` and RAG backend wired up:\n",
    ">\n",
    "> - The agent will call `rag_search` at least once  \n",
    "> - It may call `rag_get_document` if necessary  \n",
    "> - It will then stop with `ACTION: NONE` and a final **THOUGHT** that forms your answer  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d44ecce",
   "metadata": {},
   "source": [
    "\n",
    "## 7. Multi-Step Agentic RAG with Reflection (Conceptual)\n",
    "\n",
    "You can enhance the loop with **explicit reflection**:\n",
    "\n",
    "1. First round:\n",
    "   - agent retrieves & drafts an answer  \n",
    "2. Reflection step:\n",
    "   - agent (or another agent) critiques:\n",
    "     - ‚ÄúIs the answer well-supported by sources?‚Äù\n",
    "3. If not satisfied:\n",
    "   - refine queries  \n",
    "   - retrieve more  \n",
    "   - update answer  \n",
    "\n",
    "This can be implemented with:\n",
    "\n",
    "- additional roles (Critic Agent)  \n",
    "- or additional steps in the same agent loop  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46a962",
   "metadata": {},
   "source": [
    "\n",
    "### 7.1 Example Reflection Prompt (Concept Only)\n",
    "\n",
    "> ‚ÄúGiven the question, the retrieved context, and your draft answer, analyze:\n",
    "> \n",
    "> - Did you use the most relevant parts of the context?\n",
    "> - Did you hallucinate anything not supported?\n",
    "> - Are there any obvious missing angles?\n",
    "> \n",
    "> If issues exist, propose:\n",
    "> \n",
    "> - a refined retrieval query, or\n",
    "> - a corrected answer, or both.‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1312f845",
   "metadata": {},
   "source": [
    "\n",
    "## 8. Agentic RAG Design Checklist\n",
    "\n",
    "When designing Agentic RAG in your real system:\n",
    "\n",
    "- [ ] Does the agent know **when** to use retrieval?  \n",
    "- [ ] Does it know which **retrieval tool** to use? (dense/sparse/hybrid)  \n",
    "- [ ] Is there a **limit** on retrieval calls per request?  \n",
    "- [ ] Are retrieved chunks:\n",
    "  - logged?\n",
    "  - traceable to sources?  \n",
    "- [ ] Does the agent ever **self-check** its answer?  \n",
    "- [ ] Are there **fallback behaviors**:\n",
    "  - low-confidence answer\n",
    "  - ‚ÄúI don‚Äôt know‚Äù\n",
    "  - ask user for clarification  \n",
    "\n",
    "Combined with your **RAG Universe** and **Agents Universe**, this notebook:\n",
    "\n",
    "- completes the conceptual & practical bridge for **Agentic RAG**,  \n",
    "- and prepares you for the next notebooks:\n",
    "\n",
    "  - `09_MCP_with_Agents.ipynb`\n",
    "  - `10_Full_RAG_Agents_MCP.ipynb`\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
