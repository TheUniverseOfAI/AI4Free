{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb424a3",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“˜ RAG Learning Roadmap â€” Aligned with Complete TOC\n",
    "\n",
    "This notebook is a **guided learning roadmap** for Retrieval-Augmented Generation (RAG),  \n",
    "**fully aligned** with your 32-chapter Table of Contents (TOC).\n",
    "\n",
    "> âœ… Use this as your **master study planner**.  \n",
    "> âœ… Check things off as you learn them.  \n",
    "> âœ… Add your own notes and code cells under each phase.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c441025e",
   "metadata": {},
   "source": [
    "\n",
    "## ðŸ”— Roadmap â†” TOC Alignment (High-Level)\n",
    "\n",
    "| **Roadmap Phase** | **Focus** | **Aligned TOC Chapters** |\n",
    "|-------------------|-----------|---------------------------|\n",
    "| Phase 1 â€” Foundations | Concepts & background | Ch. 1â€“3 |\n",
    "| Phase 2 â€” Core RAG Pipeline | Main building blocks | Ch. 4â€“13 |\n",
    "| Phase 3 â€” RAG Types & Variants | Different RAG designs | Ch. 14â€“17 |\n",
    "| Phase 4 â€” Evaluation & Observability | Quality & debugging | Ch. 18â€“20 |\n",
    "| Phase 5 â€” Performance Engineering | Speed & cost | Ch. 21â€“23 |\n",
    "| Phase 6 â€” System Architecture & Enterprise | Real-world systems | Ch. 24â€“26 |\n",
    "| Phase 7 â€” Frameworks & Deployment | Tools & infra | Ch. 27â€“29 |\n",
    "| Phase 8 â€” Frontier Research | RAG 2.0 & beyond | Ch. 30â€“32 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53719551",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ðŸŸ¦ Phase 1 â€” Foundations (TOC Ch. 1â€“3)\n",
    "\n",
    "**Goal:** Build enough conceptual understanding of RAG and LLMs so that all later details \"click\".  \n",
    "**Estimated time:** 3â€“7 days (depending on prior LLM background)\n",
    "\n",
    "### ðŸŽ¯ Learning Outcomes\n",
    "- Understand what RAG is and why it exists.\n",
    "- Know how RAG compares to fine-tuning.\n",
    "- Know where RAG fits in the LLM / AI stack.\n",
    "- Understand basic LLM internals relevant to RAG.\n",
    "\n",
    "### ðŸ“š Linked TOC Chapters\n",
    "- **Ch. 1 â€” Introduction to RAG**\n",
    "  - 1.1 What Is Retrieval-Augmented Generation  \n",
    "  - 1.2 Why RAG Exists  \n",
    "  - 1.3 RAG vs Fine-Tuning  \n",
    "  - 1.4 RAG in the LLM System Stack  \n",
    "  - 1.5 When RAG Fails / When It Dominates  \n",
    "- **Ch. 2 â€” Pre-RAG Landscape**\n",
    "- **Ch. 3 â€” LLM Knowledge Requirements**\n",
    "\n",
    "### âœ… Checklists\n",
    "\n",
    "**Conceptual RAG**\n",
    "- [ ] I can define RAG in 2â€“3 sentences.\n",
    "- [ ] I can explain why RAG is needed even when models are \"trained on the internet\".\n",
    "- [ ] I can compare RAG vs fine-tuning with pros/cons.\n",
    "\n",
    "**Pre-RAG Landscape**\n",
    "- [ ] I understand TF-IDF, BM25 at a high level.\n",
    "- [ ] I know what \"embeddings\" are conceptually (without equations).\n",
    "\n",
    "**LLM Basics**\n",
    "- [ ] I understand tokens & context windows.\n",
    "- [ ] I know what hallucination means and why it happens.\n",
    "- [ ] I understand the role of system vs user prompts.\n",
    "\n",
    "### âœï¸ Your Notes (add under this cell)\n",
    "Create new text/code cells below and summarize what you learned from videos, docs, or articles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46b5bd",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ðŸŸ© Phase 2 â€” Core RAG Pipeline (TOC Ch. 4â€“13)\n",
    "\n",
    "**Goal:** Be able to implement a **basic but solid** RAG pipeline end-to-end.  \n",
    "**Estimated time:** 2â€“4 weeks\n",
    "\n",
    "### ðŸŽ¯ Learning Outcomes\n",
    "- Ingest & clean data.\n",
    "- Chunk documents effectively.\n",
    "- Create embeddings and store them in a vector DB.\n",
    "- Implement retrieval & reranking.\n",
    "- Build prompts that combine user query + retrieved context.\n",
    "- Generate grounded answers.\n",
    "\n",
    "### ðŸ“š Linked TOC Chapters\n",
    "- **Ch. 4 â€” Data Preparation**\n",
    "- **Ch. 5 â€” Chunking Strategies**\n",
    "- **Ch. 6 â€” Embeddings**\n",
    "- **Ch. 7 â€” Vector Databases**\n",
    "- **Ch. 8 â€” Retrieval Techniques**\n",
    "- **Ch. 9 â€” Reranking**\n",
    "- **Ch. 10 â€” Retrieval Optimization**\n",
    "- **Ch. 11 â€” Prompt Engineering for RAG**\n",
    "- **Ch. 12 â€” Answer Generation**\n",
    "- **Ch. 13 â€” Advanced Generation Strategies**\n",
    "\n",
    "### âœ… Checklists (By Topic)\n",
    "\n",
    "**4. Data Preparation**\n",
    "- [ ] I can list typical RAG data sources (PDF, HTML, DB, API).  \n",
    "- [ ] I know basic cleaning & normalization steps.  \n",
    "- [ ] I understand the role of metadata (title, section, date, author, tags).  \n",
    "\n",
    "**5. Chunking Strategies**\n",
    "- [ ] I can implement simple fixed-size chunking.\n",
    "- [ ] I can implement overlapping window chunking.\n",
    "- [ ] I know what recursive / semantic chunking is.\n",
    "- [ ] I understand why chunk size and overlap affect retrieval quality.\n",
    "\n",
    "**6. Embeddings**\n",
    "- [ ] I know the difference between dense vs sparse embeddings.\n",
    "- [ ] I can call at least one embedding API/model (e.g. OpenAI, local).\n",
    "- [ ] I know that embedding dimension and model choice matter.\n",
    "- [ ] I know what multi-vector / cross-encoder embeddings are (conceptually).\n",
    "\n",
    "**7. Vector Databases**\n",
    "- [ ] I understand what a vector DB does vs a normal DB.\n",
    "- [ ] I can index documents into at least one vector DB (FAISS / Chroma / Pinecone / etc.).\n",
    "- [ ] I know what k-NN and ANN (approximate nearest neighbor) mean at a high level.\n",
    "- [ ] I know about HNSW / IVF / PQ as index families (names + rough purpose).\n",
    "\n",
    "**8â€“10. Retrieval, Reranking, Optimization**\n",
    "- [ ] I can implement basic top-k retrieval.\n",
    "- [ ] I can filter by metadata (e.g. document type, date, tag).\n",
    "- [ ] I understand hybrid retrieval (BM25 + vectors) conceptually.\n",
    "- [ ] I know what rerankers (cross-encoders / LLM-based) do.\n",
    "- [ ] I understand query expansion / rewriting in RAG.\n",
    "\n",
    "**11â€“13. Prompting & Generation**\n",
    "- [ ] I can build a prompt template that injects retrieved context.\n",
    "- [ ] I know how to require citations in the answer.\n",
    "- [ ] I understand the idea of LLM-as-a-judge and LLM-as-a-reranker.\n",
    "- [ ] I know that advanced strategies exist (RAG-Fusion, ReAct+RAG, GraphRAG, etc.).\n",
    "\n",
    "### ðŸ§ª Milestone Project for Phase 2\n",
    "> **Goal:** Build a simple \"Ask Your Docs\" RAG app.\n",
    "\n",
    "- [ ] Load a small set of documents.  \n",
    "- [ ] Chunk, embed, and index them in a vector DB.  \n",
    "- [ ] Implement a function: `answer_query(query)` that retrieves, injects context, and calls an LLM.  \n",
    "- [ ] Print both **answer** and the **source chunks** used.  \n",
    "\n",
    "Add code cells under this section to implement your first full pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08849add",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ðŸŸ§ Phase 3 â€” RAG Types & Variants (TOC Ch. 14â€“17)\n",
    "\n",
    "**Goal:** Understand and implement more **powerful RAG flavors** beyond the basic 2-step pipeline.  \n",
    "**Estimated time:** 1â€“3 weeks\n",
    "\n",
    "### ðŸŽ¯ Learning Outcomes\n",
    "- Know different RAG variants and when to use them.\n",
    "- Understand Fusion, HyDE, GraphRAG, and Agentic RAG conceptually.\n",
    "- Extend your basic pipeline with at least one advanced design.\n",
    "\n",
    "### ðŸ“š Linked TOC Chapters\n",
    "- **Ch. 14 â€” Basic RAG**\n",
    "- **Ch. 15 â€” Advanced RAG Variants (RAG-Fusion, HyDE, GraphRAG, etc.)**\n",
    "- **Ch. 16 â€” Multi-Modal RAG**\n",
    "- **Ch. 17 â€” Agentic RAG**\n",
    "\n",
    "### âœ… Checklists\n",
    "\n",
    "**Basic vs Advanced RAG**\n",
    "- [ ] I can explain the standard 2-stage RAG pipeline.\n",
    "- [ ] I can describe how RAG-Fusion differs from basic RAG.\n",
    "- [ ] I know what HyDE does (hypothetical document generation).\n",
    "\n",
    "**Multi-Modal RAG**\n",
    "- [ ] I know that RAG can retrieve images / audio / other modalities.\n",
    "- [ ] I can describe how OCR fits into document ingestion.\n",
    "\n",
    "**Agentic RAG**\n",
    "- [ ] I understand the idea of an agent calling tools (retriever, DB, APIs).\n",
    "- [ ] I can explain plannerâ€“executor patterns in agentic RAG.\n",
    "- [ ] I know how RAG can serve as an \"information tool\" for an agent.\n",
    "\n",
    "### ðŸ§ª Milestone Project for Phase 3\n",
    "Pick **one** of the following:\n",
    "\n",
    "- [ ] Implement **Multi-query RAG** or **RAG-Fusion** on top of your existing pipeline.  \n",
    "- [ ] Or: Implement a simple **ReAct-style agent** that decides when to call the retriever vs answer directly.  \n",
    "\n",
    "Add notes and code cells under this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d38a4",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ðŸŸ¥ Phase 4 â€” Evaluation & Observability (TOC Ch. 18â€“20)\n",
    "\n",
    "**Goal:** Learn how to **measure**, **debug**, and **improve** RAG quality.  \n",
    "**Estimated time:** 1â€“2 weeks\n",
    "\n",
    "### ðŸŽ¯ Learning Outcomes\n",
    "- Understand classical IR metrics (precision, recall, MRR).\n",
    "- Use modern RAG tools (RAGAS, TruLens, LLM-as-a-judge).\n",
    "- Add logging and tracing around your RAG system.\n",
    "\n",
    "### ðŸ“š Linked TOC Chapters\n",
    "- **Ch. 18 â€” RAG Evaluation**\n",
    "- **Ch. 19 â€” Automatic RAG Evaluation (RAGAS, TruLens, LLM-as-a-judge)**  \n",
    "- **Ch. 20 â€” Observability (logging, spans, diagnostics)**\n",
    "\n",
    "### âœ… Checklists\n",
    "\n",
    "**Evaluation Metrics**\n",
    "- [ ] I know what precision, recall, F1, and MRR mean in retrieval.\n",
    "- [ ] I can generate a small labeled dataset of questions + expected docs.\n",
    "\n",
    "**RAGAS / LLM-as-a-Judge**\n",
    "- [ ] I understand the main RAGAS metrics (relevance, faithfulness, answer correctness) conceptually.\n",
    "- [ ] I know what \"LLM-as-a-judge\" means in evaluation.\n",
    "- [ ] I can sketch how to evaluate my pipeline with these metrics.\n",
    "\n",
    "**Observability**\n",
    "- [ ] I log query, retrieved docs, and final answer for each request.\n",
    "- [ ] I can inspect problematic queries and see where the pipeline failed (retrieval vs generation).\n",
    "- [ ] I understand the value of span tracing and telemetry for RAG.\n",
    "\n",
    "### ðŸ§ª Milestone Project for Phase 4\n",
    "- [ ] Create a tiny evaluation set (e.g. 20â€“50 Q&A pairs).  \n",
    "- [ ] Log retrieval and answers for that set.  \n",
    "- [ ] Manually inspect or use an LLM-as-a-judge approach to rate quality.  \n",
    "- [ ] Write notes on **common failure modes** you observe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4195049",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ðŸŸ¨ Phase 5 â€” Performance Engineering (TOC Ch. 21â€“23)\n",
    "\n",
    "**Goal:** Make your RAG system **fast, cheap, and scalable enough** for real-world usage.  \n",
    "**Estimated time:** 1â€“2 weeks (initial), continuous improvement later\n",
    "\n",
    "### ðŸŽ¯ Learning Outcomes\n",
    "- Understand main latency sources (embedding, retrieval, generation).\n",
    "- Use caching and batching to reduce cost/latency.\n",
    "- Understand basic scaling concepts for vector search.\n",
    "\n",
    "### ðŸ“š Linked TOC Chapters\n",
    "- **Ch. 21 â€” Latency Optimization**\n",
    "- **Ch. 22 â€” Cost Optimization**\n",
    "- **Ch. 23 â€” Scalability**\n",
    "\n",
    "### âœ… Checklists\n",
    "\n",
    "**Latency**\n",
    "- [ ] I can profile where time is spent in my pipeline.\n",
    "- [ ] I understand the impact of k (top-k) and chunk size on latency.\n",
    "- [ ] I know about parallel retrieval and batch embeddings.\n",
    "\n",
    "**Cost**\n",
    "- [ ] I know which parts of the system cost the most (embeddings vs generation).\n",
    "- [ ] I can reduce context size without breaking answer quality too much.\n",
    "- [ ] I know what semantic caching is conceptually.\n",
    "\n",
    "**Scalability**\n",
    "- [ ] I know the basic idea of sharding vector indexes.\n",
    "- [ ] I understand the difference between horizontal and vertical scaling.\n",
    "- [ ] I can sketch how to scale from \"toy\" to \"production\" RAG.\n",
    "\n",
    "### ðŸ§ª Milestone Project for Phase 5\n",
    "- [ ] Measure latency of your current pipeline end-to-end.  \n",
    "- [ ] Add at least **one** of: caching, batching, or parallelism.  \n",
    "- [ ] Re-measure and note the improvements.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95fd802",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ðŸŸª Phase 6 â€” System Architecture & Enterprise RAG (TOC Ch. 24â€“26)\n",
    "\n",
    "**Goal:** Think like an **architect** designing RAG for teams/companies.  \n",
    "**Estimated time:** 1â€“2 weeks\n",
    "\n",
    "### ðŸŽ¯ Learning Outcomes\n",
    "- Understand common RAG architecture patterns (local, cloud, hybrid).\n",
    "- See how knowledge graphs and RAG can combine.\n",
    "- Understand multi-tenant, access control, and governance issues.\n",
    "\n",
    "### ðŸ“š Linked TOC Chapters\n",
    "- **Ch. 24 â€” RAG Architecture Patterns**\n",
    "- **Ch. 25 â€” Knowledge Graph + RAG**\n",
    "- **Ch. 26 â€” Enterprise RAG**\n",
    "\n",
    "### âœ… Checklists\n",
    "\n",
    "**Architecture Patterns**\n",
    "- [ ] I can sketch 2â€“3 different RAG architectures (local-only, cloud-only, hybrid).\n",
    "- [ ] I understand where vector DB, app server, and LLM API sit in the diagram.\n",
    "\n",
    "**Knowledge Graph + RAG (GraphRAG)**\n",
    "- [ ] I know what a knowledge graph is at a high level.\n",
    "- [ ] I can explain how graph signals can help ranking and retrieval.\n",
    "- [ ] I can describe the idea of GraphRAG pipeline.\n",
    "\n",
    "**Enterprise Concerns**\n",
    "- [ ] I understand role-based access control in a RAG context.\n",
    "- [ ] I know why data governance and PII matter in RAG.\n",
    "- [ ] I can sketch a multi-tenant RAG system at a high level.\n",
    "\n",
    "### ðŸ§ª Milestone Project for Phase 6\n",
    "- [ ] Draw at least one detailed RAG architecture diagram for a real use case you care about (e.g., finance assistant, academic Q&A, code reviewer).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f309e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ðŸŸ« Phase 7 â€” Frameworks & Deployment (TOC Ch. 27â€“29)\n",
    "\n",
    "**Goal:** Become comfortable with **RAG frameworks and infra** so you can ship real apps.  \n",
    "**Estimated time:** 2â€“3 weeks for first version\n",
    "\n",
    "### ðŸŽ¯ Learning Outcomes\n",
    "- Use at least one RAG framework deeply (LangChain, LlamaIndex, etc.).\n",
    "- Understand vector DB operations beyond \"insert & query\".\n",
    "- Containerize and deploy a simple RAG service.\n",
    "\n",
    "### ðŸ“š Linked TOC Chapters\n",
    "- **Ch. 27 â€” RAG Frameworks (LangChain, LlamaIndex, Haystack, DSPy, Semantic Kernel)**  \n",
    "- **Ch. 28 â€” Vector Databases (Deep Dive)**  \n",
    "- **Ch. 29 â€” Deployment (Docker, Serverless, K8s, CI/CD)**  \n",
    "\n",
    "### âœ… Checklists\n",
    "\n",
    "**Frameworks**\n",
    "- [ ] I can implement a RAG pipeline using at least one framework.\n",
    "- [ ] I understand the advantages and tradeoffs of that framework.\n",
    "\n",
    "**Vector DB Deep Dive**\n",
    "- [ ] I know how to manage indexes, replication, and filtering in my chosen vector DB.\n",
    "- [ ] I can batch insert documents efficiently.\n",
    "\n",
    "**Deployment**\n",
    "- [ ] I can wrap my RAG pipeline in an API (FastAPI / Node.js / etc.).\n",
    "- [ ] I can containerize it with Docker.\n",
    "- [ ] I understand the basics of deploying to a cloud provider or serverless platform.\n",
    "- [ ] I know what CI/CD means in this context.\n",
    "\n",
    "### ðŸ§ª Milestone Project for Phase 7\n",
    "- [ ] Turn your RAG pipeline into a small **web API or web app** and deploy it somewhere (even if just a test environment).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6a2af",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "# ðŸŸ¦ Phase 8 â€” Frontier Research & RAG 2.0 (TOC Ch. 30â€“32)\n",
    "\n",
    "**Goal:** Understand where RAG is **heading next**, so your skills stay future-proof.  \n",
    "**Estimated time:** Ongoing / as curiosity-driven\n",
    "\n",
    "### ðŸŽ¯ Learning Outcomes\n",
    "- Know key ideas behind RAG 2.0 / next-generation RAG.\n",
    "- Understand self-correcting, dynamic retrieval, and model-assisted retrieval.\n",
    "- Be able to read and roughly understand RAG research papers and blogs.\n",
    "\n",
    "### ðŸ“š Linked TOC Chapters\n",
    "- **Ch. 30 â€” RAG 2.0**\n",
    "- **Ch. 31 â€” Model-Assisted Retrieval**\n",
    "- **Ch. 32 â€” Future of RAG**\n",
    "\n",
    "### âœ… Checklists\n",
    "\n",
    "**RAG 2.0 Concepts**\n",
    "- [ ] I know what self-correcting RAG means.\n",
    "- [ ] I can explain dynamic / adaptive retrieval at a high level.\n",
    "- [ ] I know what memory-augmented RAG refers to.\n",
    "\n",
    "**Model-Assisted Retrieval**\n",
    "- [ ] I understand generative search augmentation.\n",
    "- [ ] I know the idea of model-driven indexing and embedding tuning.\n",
    "\n",
    "**Future Directions**\n",
    "- [ ] I can describe how RAG, agents, and multimodal LLMs fit together.\n",
    "- [ ] I keep a personal list of interesting RAG research papers / repos.\n",
    "\n",
    "### ðŸ§ª Milestone Project for Phase 8\n",
    "- [ ] Pick **one** advanced topic (e.g., GraphRAG, RAG-Fusion, dynamic retrieval) and write a 1â€“2 page summary in your own words, with diagrams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7724e6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## âœ… How to Use This Notebook\n",
    "\n",
    "1. **Go phase by phase.**  \n",
    "2. For each section, read the checklist **top to bottom**.  \n",
    "3. Add your own **notes, links, and code** in new cells under each phase.  \n",
    "4. Treat the TOC as your **full universe of topics**, and this roadmap as your **guided path** through it.\n",
    "\n",
    "You can duplicate this notebook and customize it for:\n",
    "\n",
    "- General RAG learning  \n",
    "- Domain-specific RAG (medical, legal, finance, academic, code, etc.)  \n",
    "- Specific tech stacks (Python, Node.js, LangChain, LlamaIndex, etc.)  \n",
    "\n",
    "Happy building ðŸš€\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
